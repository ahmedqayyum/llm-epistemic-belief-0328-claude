# Downloaded Papers

## Core Papers (Epistemic Belief in LLMs)

1. **Belief in the Machine: Investigating Epistemological Blind Spots of Language Models** (papers/2410.21195_belief_in_the_machine.pdf)
   - Authors: Suzgun, Gur, Bianchi, Ho, Icard, Jurafsky, Zou
   - Year: 2024
   - arXiv: 2410.21195
   - Why relevant: Most directly relevant—introduces KaBLE benchmark (13K questions) testing LMs on fact/belief/knowledge distinctions across 13 tasks. Key finding: LMs achieve 86% on factual but drop to 54% on first-person false beliefs.

2. **Defining Knowledge: Bridging Epistemology and Large Language Models** (papers/emnlp2024_defining_knowledge.pdf)
   - Authors: Fierro, Dhar, Stamatiou, Garneau, Søgaard
   - Year: 2024 (EMNLP)
   - Why relevant: Formalizes 5 epistemological definitions of knowledge for LLMs (true belief, justified, sui generis, virtue, predictive). Provides theoretical grounding.

3. **Epistemic Integrity in Large Language Models** (papers/2411.06528_epistemic_integrity_llm.pdf)
   - Authors: arXiv: 2411.06528
   - Year: 2024
   - Why relevant: Examines whether LLMs maintain consistent epistemic standards across contexts.

4. **Reasoning Models Better Express Their Confidence** (papers/2505.14489_reasoning_models_confidence.pdf)
   - Authors: Yoon et al.
   - Year: 2025
   - arXiv: 2505.14489
   - Why relevant: Shows reasoning models use epistemic markers for uncertainty; provides epistemic QA datasets.

5. **On the Notion that Language Models Reason** (papers/2511.11810_notion_lm_reason.pdf)
   - Authors: Højer
   - Year: 2025
   - arXiv: 2511.11810
   - Why relevant: Philosophical argument that LMs are statistical pattern matchers, not genuine reasoners.

6. **Kalshibench: Evaluating Epistemic Calibration** (papers/2512.16030_kalshibench_epistemic_calibration.pdf)
   - Authors: arXiv: 2512.16030
   - Year: 2025
   - Why relevant: Epistemic calibration of LLMs using prediction markets.

7. **Beyond Accuracy: Rethinking Hallucination** (papers/2509.13345_beyond_accuracy_hallucination.pdf)
   - Year: 2025
   - Why relevant: Connects hallucination to epistemic gaps in LLMs.

## Theory of Mind Papers

8. **Evaluating Large Language Models in Theory of Mind Tasks** (papers/2302.02083_evaluating_llm_tom.pdf)
   - Authors: Kosinski
   - Year: 2023; PNAS 2024
   - Why relevant: First systematic false-belief evaluation of LLMs.

9. **SymbolicToM: Plug-and-Play Multi-Character Belief Tracker** (papers/2306.00924_symbolic_tom.pdf)
   - Authors: Sclar et al.
   - Year: 2023 (ACL)
   - Why relevant: Algorithmic approach to belief tracking in LLMs.

10. **TMBench: Benchmarking Theory of Mind in LLMs** (papers/2402.15052_tmbench.pdf)
    - Authors: Chen et al.
    - Year: 2024
    - Why relevant: Comprehensive ToM benchmark; contamination analysis.

11. **LLMs Achieve Adult Human Performance on Higher-Order ToM** (papers/2405.18870_llm_adult_tom.pdf)
    - Authors: Street et al.
    - Year: 2024
    - Why relevant: Higher-order ToM evaluation with adult human benchmarks.

12. **Dissecting Ullman Variations with SCALPEL** (papers/2406.14737_scalpel_false_belief.pdf)
    - Authors: Pi et al.
    - Year: 2024
    - Why relevant: Analysis of why LLMs fail at false-belief task variations.

13. **Mind Your Theory: ToM Goes Deeper Than Reasoning** (papers/2412.13631_mind_your_theory.pdf)
    - Year: 2024
    - Why relevant: Argues for deeper mentalizing benchmarks beyond passive QA.

14. **Position: Theory of Mind Benchmarks are Broken** (papers/2412.19726_tom_benchmarks_broken.pdf)
    - Year: 2024
    - Why relevant: Critique of current ToM benchmarks; call for interactive evaluation.

15. **A Survey of Theory of Mind in LLMs** (papers/2502.06470_tom_survey.pdf)
    - Authors: Nguyen
    - Year: 2025 (AAAI Workshop)
    - Why relevant: Comprehensive survey of ToM in LLMs.

16. **Theory of Mind in LLMs: Assessment and Enhancement** (papers/2505.00026_tom_assessment_enhancement.pdf)
    - Year: 2025 (ACL)
    - Why relevant: Review of ToM evaluation and improvement methods.

17. **CogToM: Comprehensive Theory of Mind Benchmark** (papers/2601.15628_cogtom.pdf)
    - Year: 2026
    - Why relevant: Latest ToM benchmark with 46 tasks and 8,513 entries.
