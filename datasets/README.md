# Downloaded Datasets

This directory contains datasets for the research project. Data files are NOT
committed to git due to size. Follow the download instructions below.

## Dataset 1: agentlans/fact-or-opinion

### Overview
- **Source**: https://huggingface.co/datasets/agentlans/fact-or-opinion
- **Size**: 41,549 samples (33,239 train / 8,310 test)
- **Format**: HuggingFace Dataset (JSON/Parquet)
- **Task**: Multi-label fact vs opinion classification
- **Labels**: Fact, Opinion, Both, Neither
- **Languages**: 15 (ar, am, bn, de, en, es, fr, hi, it, ja, ko, pt-br, ru, sw, zh-cn)
- **License**: ODC-BY
- **Label Distribution (train)**: Fact: 7,264 | Opinion: 8,819 | Both: 8,754 | Neither: 8,402

### Download Instructions

**Using HuggingFace (recommended):**
```python
from datasets import load_dataset
dataset = load_dataset("agentlans/fact-or-opinion")
dataset.save_to_disk("datasets/fact_or_opinion")
```

### Loading the Dataset
```python
from datasets import load_from_disk
dataset = load_from_disk("datasets/fact_or_opinion")
# Or directly:
from datasets import load_dataset
dataset = load_dataset("agentlans/fact-or-opinion")
```

### Sample Data
See `fact_or_opinion_samples.json` for 20 example records.

### Notes
- Synthetic dataset generated by ChatGPT, Claude Sonnet 4, Gemini 2.5 Flash
- For experiments, filter to `language == "en"` for English-only analysis
- 4-way classification: can be binarized (Fact vs Opinion) or used as-is

---

## Dataset 2: KaBLE (Knowledge and Belief Language Evaluation)

### Overview
- **Source**: https://github.com/suzgunmirac/belief-in-the-machine
- **Size**: 13,000 questions (1,000 per task Ã— 13 tasks)
- **Format**: JSONL files (one per task)
- **Task**: Epistemic reasoning across 13 task types
- **Splits**: Each JSONL contains both factual and false variants
- **License**: See repo

### Download Instructions

**From GitHub:**
```bash
git clone https://github.com/suzgunmirac/belief-in-the-machine.git
cp -r belief-in-the-machine/kable-dataset datasets/kable/
```

### Loading the Dataset
```python
import json
with open("datasets/kable/confirmation-of-first-person-belief.jsonl") as f:
    data = [json.loads(line) for line in f]
```

### Task Files
- `direct-fact-verification.jsonl`
- `verification-of-assertion.jsonl`
- `verification-of-first-person-knowledge.jsonl`
- `verification-of-first-person-belief.jsonl`
- `confirmation-of-first-person-belief.jsonl`
- `second-guessing-first-person-belief.jsonl`
- `confirmation-of-third-person-belief-james.jsonl`
- `confirmation-of-third-person-belief-mary.jsonl`
- `correct-attribution-of-belief-james-mary.jsonl`
- `correct-attribution-of-belief-mary-james.jsonl`
- `verification-of-recursive-knowledge.jsonl`
- `confirmation-of-recursive-knowledge.jsonl`
- `awareness-of-recursive-knowledge.jsonl`

### Notes
- Each record contains: experiment_setup, subject, idx, type (factual/false), raw_sentence, query
- 10 domains: Math, Economics, History, Science, Technology, Philosophy/Arts, Law, Geography, Biology/Medicine, Linguistics
- 500 factual + 500 false seed sentences form the basis

---

## Dataset 3: DKYoon/r1-triviaqa-epistemic

### Overview
- **Source**: https://huggingface.co/datasets/DKYoon/r1-triviaqa-epistemic
- **Size**: 1,000 validation samples
- **Format**: HuggingFace Dataset
- **Task**: QA with epistemic reasoning traces
- **Columns**: question, answers, model_think, prompt

### Download Instructions
```python
from datasets import load_dataset
dataset = load_dataset("DKYoon/r1-triviaqa-epistemic")
```

### Notes
- Contains reasoning model traces with epistemic markers
- Useful for qualitative analysis of how models express uncertainty
- See `r1_triviaqa_epistemic_samples.json` for samples

---

## Dataset 4: DKYoon/r1-nonambigqa-epistemic

### Overview
- **Source**: https://huggingface.co/datasets/DKYoon/r1-nonambigqa-epistemic
- **Size**: 1,000 validation samples
- **Format**: HuggingFace Dataset
- **Task**: QA with epistemic reasoning traces
- **Columns**: question, answers, model_think, prompt

### Download Instructions
```python
from datasets import load_dataset
dataset = load_dataset("DKYoon/r1-nonambigqa-epistemic")
```

### Notes
- Companion to triviaqa-epistemic with non-ambiguous questions
- See `r1_nonambigqa_epistemic_samples.json` for samples
